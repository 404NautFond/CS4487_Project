{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, base_width=64, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        \n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_classes=10, groups=1, width_per_group=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, 3)\n",
    "        self.layer2 = self._make_layer(block, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, 3, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Start Training, Resnet-50!\n",
      "[epoch:1] Loss: 2.094 | Acc: 24.212% \n",
      "Test accuracy: 34.260%\n",
      "[epoch:2] Loss: 1.725 | Acc: 37.118% \n",
      "Test accuracy: 40.700%\n",
      "[epoch:3] Loss: 1.573 | Acc: 42.962% \n",
      "Test accuracy: 45.240%\n",
      "[epoch:4] Loss: 1.467 | Acc: 46.376% \n",
      "Test accuracy: 46.280%\n",
      "[epoch:5] Loss: 1.394 | Acc: 49.448% \n",
      "Test accuracy: 50.110%\n",
      "[epoch:6] Loss: 1.330 | Acc: 51.822% \n",
      "Test accuracy: 51.440%\n",
      "[epoch:7] Loss: 1.273 | Acc: 54.198% \n",
      "Test accuracy: 52.390%\n",
      "[epoch:8] Loss: 1.229 | Acc: 55.888% \n",
      "Test accuracy: 55.500%\n",
      "[epoch:9] Loss: 1.180 | Acc: 57.798% \n",
      "Test accuracy: 55.910%\n",
      "[epoch:10] Loss: 1.137 | Acc: 59.284% \n",
      "Test accuracy: 58.300%\n",
      "[epoch:11] Loss: 1.103 | Acc: 60.558% \n",
      "Test accuracy: 58.590%\n",
      "[epoch:12] Loss: 1.064 | Acc: 62.052% \n",
      "Test accuracy: 59.160%\n",
      "[epoch:13] Loss: 1.034 | Acc: 63.230% \n",
      "Test accuracy: 59.370%\n",
      "[epoch:14] Loss: 1.006 | Acc: 64.182% \n",
      "Test accuracy: 61.400%\n",
      "[epoch:15] Loss: 0.974 | Acc: 65.292% \n",
      "Test accuracy: 62.420%\n",
      "[epoch:16] Loss: 0.953 | Acc: 65.914% \n",
      "Test accuracy: 62.660%\n",
      "[epoch:17] Loss: 0.924 | Acc: 67.078% \n",
      "Test accuracy: 63.880%\n",
      "[epoch:18] Loss: 0.897 | Acc: 68.024% \n",
      "Test accuracy: 64.870%\n",
      "[epoch:19] Loss: 0.884 | Acc: 68.674% \n",
      "Test accuracy: 64.750%\n",
      "[epoch:20] Loss: 0.862 | Acc: 69.664% \n",
      "Test accuracy: 64.730%\n",
      "[epoch:21] Loss: 0.836 | Acc: 70.392% \n",
      "Test accuracy: 65.600%\n",
      "[epoch:22] Loss: 0.830 | Acc: 70.522% \n",
      "Test accuracy: 67.180%\n",
      "[epoch:23] Loss: 0.806 | Acc: 71.390% \n",
      "Test accuracy: 65.960%\n",
      "[epoch:24] Loss: 0.793 | Acc: 71.828% \n",
      "Test accuracy: 67.560%\n",
      "[epoch:25] Loss: 0.774 | Acc: 72.490% \n",
      "Test accuracy: 68.010%\n",
      "[epoch:26] Loss: 0.761 | Acc: 73.100% \n",
      "Test accuracy: 67.370%\n",
      "[epoch:27] Loss: 0.744 | Acc: 73.654% \n",
      "Test accuracy: 68.280%\n",
      "[epoch:28] Loss: 0.731 | Acc: 74.054% \n",
      "Test accuracy: 68.140%\n",
      "[epoch:29] Loss: 0.716 | Acc: 74.632% \n",
      "Test accuracy: 68.610%\n",
      "[epoch:30] Loss: 0.701 | Acc: 75.220% \n",
      "Test accuracy: 69.080%\n",
      "[epoch:31] Loss: 0.695 | Acc: 75.268% \n",
      "Test accuracy: 69.260%\n",
      "[epoch:32] Loss: 0.684 | Acc: 75.722% \n",
      "Test accuracy: 69.830%\n",
      "[epoch:33] Loss: 0.666 | Acc: 76.380% \n",
      "Test accuracy: 70.290%\n",
      "[epoch:34] Loss: 0.658 | Acc: 76.622% \n",
      "Test accuracy: 69.500%\n",
      "[epoch:35] Loss: 0.637 | Acc: 77.240% \n",
      "Test accuracy: 70.380%\n",
      "[epoch:36] Loss: 0.633 | Acc: 77.550% \n",
      "Test accuracy: 70.560%\n",
      "[epoch:37] Loss: 0.622 | Acc: 77.968% \n",
      "Test accuracy: 69.640%\n",
      "[epoch:38] Loss: 0.609 | Acc: 78.224% \n",
      "Test accuracy: 70.670%\n",
      "[epoch:39] Loss: 0.593 | Acc: 78.934% \n",
      "Test accuracy: 70.950%\n",
      "[epoch:40] Loss: 0.599 | Acc: 78.700% \n",
      "Test accuracy: 70.450%\n",
      "[epoch:41] Loss: 0.579 | Acc: 79.200% \n",
      "Test accuracy: 71.530%\n",
      "[epoch:42] Loss: 0.570 | Acc: 79.884% \n",
      "Test accuracy: 71.470%\n",
      "[epoch:43] Loss: 0.563 | Acc: 79.872% \n",
      "Test accuracy: 71.870%\n",
      "[epoch:44] Loss: 0.552 | Acc: 80.330% \n",
      "Test accuracy: 71.940%\n",
      "[epoch:45] Loss: 0.540 | Acc: 80.642% \n",
      "Test accuracy: 72.070%\n",
      "[epoch:46] Loss: 0.527 | Acc: 81.166% \n",
      "Test accuracy: 72.110%\n",
      "[epoch:47] Loss: 0.526 | Acc: 81.380% \n",
      "Test accuracy: 71.950%\n",
      "[epoch:48] Loss: 0.516 | Acc: 81.674% \n",
      "Test accuracy: 71.910%\n",
      "[epoch:49] Loss: 0.507 | Acc: 81.848% \n",
      "Test accuracy: 71.030%\n",
      "[epoch:50] Loss: 0.502 | Acc: 82.054% \n",
      "Test accuracy: 72.060%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-08228b4f5823>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCH = 128\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    " \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    " \n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    " \n",
    "trainset = torchvision.datasets.CIFAR10(root='cifar-10-batches-py', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    " \n",
    "testset = torchvision.datasets.CIFAR10(root='cifar-10-batches-py', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    " \n",
    "net = ResNet50().to(device)\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "print(\"Start Training, Resnet-50!\")\n",
    "for epoch in range(EPOCH):\n",
    "    net.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    data_num = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        length = len(trainloader)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).cpu().sum()\n",
    "        data_num = i\n",
    "    print('[epoch:%d] Loss: %.03f | Acc: %.3f%% ' \n",
    "            % (epoch + 1, sum_loss / (data_num + 1), 100. * correct / total))\n",
    "    \n",
    "    #test\n",
    "    with torch.no_grad():\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "        print('Test accuracy: %.3f%%' %(100 * correct_test / total_test))\n",
    "print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
